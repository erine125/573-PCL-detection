{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2818470-f3d4-4186-820f-0980744112d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "API_KEY = None # Set locally\n",
    "\n",
    "def translate_text(text, target_language=\"en\"):\n",
    "    \"\"\"Translate text using the Google Cloud Translation API.\"\"\"\n",
    "    api_key = API_KEY\n",
    "    url = \"https://translation.googleapis.com/language/translate/v2\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': text,\n",
    "        'target': target_language,\n",
    "        'format': 'text'\n",
    "    }\n",
    "    response = requests.post(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['data']['translations'][0]['translatedText']\n",
    "    else:\n",
    "        return \"Error: \" + response.text\n",
    "\n",
    "def translate_csv(input_file, output_file, text_column, target_language=\"en\"):\n",
    "    \"\"\"Translate a column in a CSV file and write to a new file.\"\"\"\n",
    "    df = pd.read_csv(input_file)\n",
    "    df[text_column] = df[text_column].apply(lambda text: translate_text(text, target_language))\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Translated CSV saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7a3a28c-d1be-4033-8b57-fac5a933d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated CSV saved as translated_CPCC.csv\n"
     ]
    }
   ],
   "source": [
    "input_csv = 'CCPC_Dataset.csv'  # Path to your source CSV\n",
    "output_csv = 'translated_CCPC.csv'  # Path for the translated CSV\n",
    "column_to_translate = 'text'  # Column name in your CSV that contains the text\n",
    "target_lang = 'en'  \n",
    "\n",
    "translate_csv(input_csv, output_csv, column_to_translate, target_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c02db-15c9-4d83-847a-ad84939ccf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('bert_model_EngWithStopwords') # load the model trained on English data. \n",
    "# Note that the entire model is too large to push to GitHub, so make sure to run the English data training script first, which will save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13a7ab-8418-41f6-acf5-55dec8617856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('translated_CCPC.csv')\n",
    "\n",
    "df_test['text'] = df_test['text'].apply(lambda x:clean_text(x))\n",
    "test_sentences = df_test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dde87c-2a61-4704-ad2b-2061f539d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df_test['text']:\n",
    "#     try: clean_text(i) \n",
    "#     except AttributeError:\n",
    "#         print(i)\n",
    "\n",
    "df_test['text'] = df_test['text'].apply(lambda x:clean_text(x))\n",
    "test_sentences = df_test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a8f24b-8fa4-40a3-8f3a-76a4758c97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks)\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a102d01-afc6-4681-80ed-bc8e5ba54b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for batch in test_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            output= model(b_input_ids,\n",
    "                                   token_type_ids=None,\n",
    "                                   attention_mask=b_input_mask)\n",
    "            logits = output.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "            predictions.extend(list(pred_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0862bd1-2611-4be0-9b5d-9f4e4b758394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame()\n",
    "#df_output['id'] = df_test['id'] # Do we need to add ids?\n",
    "df_output['target'] =predictions\n",
    "results_filename = 'D4_OriginalModelWithTranslation.out'\n",
    "\n",
    "df_output.to_csv(results_filename,index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e00ee-1649-45d7-a836-603ede3c44ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "\n",
    "import sys\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test_set_csv = 'translated_CCPC.csv'\n",
    "\n",
    "# read in the CSV and get the gold labels\n",
    "gold_df = pd.read_csv(test_set_csv)\n",
    "task1_gold = gold_df['target'].tolist()\n",
    "\n",
    "# read in the results file and get the system output labels\n",
    "task1_res = []\n",
    "with open(results_filename) as f:\n",
    "    for line in f:\n",
    "        task1_res.append(int(line.strip()))\n",
    "\n",
    "with open('D4_OriginalModelWithTranslation_Results.txt', 'w') as outf:\n",
    "\n",
    "    # task 1 scores\n",
    "    t1p = precision_score(task1_gold, task1_res)\n",
    "    t1r = recall_score(task1_gold, task1_res)\n",
    "    t1f = f1_score(task1_gold, task1_res)\n",
    "    # task1\n",
    "    outf.write('task1_precision:'+str(t1p)+'\\n')\n",
    "    outf.write('task1_recall:'+str(t1r)+'\\n')\n",
    "    outf.write('task1_f1:'+str(t1f)+'\\n')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
